# BabyLlama
The model architecture is RoFormer (with rotational positional embedding, grouped-query attention). Model is trained on Entire work of Shakepare. The inference is done using KV cache. <br>
<img width="542" alt="image" src="https://github.com/Sachin-Bharadwaj/BabyLlama/assets/26499326/7fb04de0-d23e-4dee-9fa3-ed5fb023c46e"> <br>
<img width="662" alt="image" src="https://github.com/Sachin-Bharadwaj/BabyLlama/assets/26499326/53fdb635-bf62-4530-9422-ec0f1c41afd5"> <br>
Here is the train/val loss curve <br>
<img width="376" alt="image" src="https://github.com/Sachin-Bharadwaj/BabyLlama/assets/26499326/c7861257-4fc9-487a-87d6-97f7858c2025">
Here are the generated sample prompts <br>
<img width="832" alt="image" src="https://github.com/Sachin-Bharadwaj/BabyLlama/assets/26499326/62b77e0c-224c-45e0-b96e-6815d85befd5">



